
# ğŸ©º Multilingual Voice-Enabled AI Healthcare Chatbot

A **multilingual AI healthcare chatbot** that accepts **live voice input**, understands the userâ€™s language automatically, processes the query using **modern NLP and Large Language Models**, and responds in the **same language** using **text and synthesized speech**.

This project demonstrates **practical experience in multilingual NLP**, **speech processing**, and **LLM-based reasoning**, making it suitable for academic submissions and industry roles.

---

## ğŸš€ Key Features

* ğŸ™ï¸ **Live voice input** via Streamlit
* ğŸ—£ï¸ **Speech-to-Text (STT)** using OpenAI Whisper
* ğŸŒ **Implicit multilingual understanding**
* ğŸ§  **LLM-based medical reasoning** using Groq (LLaMA-3)
* ğŸ”Š **Text-to-Speech (TTS)** output in the same language
* ğŸ¥ Healthcare-specific safe response design
* ğŸ§© Modular, extensible architecture

---

## ğŸ§  High-Level NLP Pipeline

```

User Speech (Any Language)
â†“
Speech-to-Text (Whisper)
â†“
Multilingual Natural Language Understanding
â†“
LLM-based Medical Reasoning (Groq - LLaMA 3)
â†“
Multilingual Text Generation
â†“
Text-to-Speech (Same Language)
â†“
Voice + Text Output

```

---

## ğŸ” Detailed Pipeline Explanation (Internals)

### 1ï¸âƒ£ Speech-to-Text (Automatic Language Recognition)

* The system uses **Whisper**, a transformer-based speech recognition model.
* Whisper performs:

  * Acoustic modeling
  * Tokenization of speech into subword units
  * **Automatic language identification**
* Output:

  * Transcribed text
  * Implicit language signal

ğŸ“Œ No explicit language classifier is required.

---

### 2ï¸âƒ£ Multilingual Natural Language Understanding

* The transcribed text may be in **any language** (English, Hindi, Tamil, etc.).
* Instead of translating manually, the system leverages a **multilingual LLM**.
* Multilingual embeddings allow semantic understanding across languages.

---

### 3ï¸âƒ£ LLM-Based Medical Reasoning (Groq + LLaMA-3)

* The core reasoning engine is **LLaMA-3**, hosted via the **Groq API**.
* The prompt enforces:

  * Medical safety constraints
  * Non-diagnostic responses
  * Response language preservation

#### Prompt strategy:

* Instruction tuning
* Contextual role prompting
* Controlled generation (low temperature)

ğŸ“Œ The model performs:

* Semantic parsing
* Intent understanding
* Contextual response generation

---

### 4ï¸âƒ£ Multilingual Text Generation

* LLaMA-3 internally represents text in a **shared latent semantic space**.
* This enables **cross-lingual generation** without explicit translation steps.
* Output is generated **in the same language as user input**.

---

### 5ï¸âƒ£ Text-to-Speech (TTS)

* Uses **Google Text-to-Speech (gTTS)**.
* Language is inferred from the response text.
* Produces a natural-sounding audio response.

---

## ğŸ§© Project Structure

```

Plan_B_AI_Doctor/
â”‚
â”œâ”€â”€ streamlit_app.py          # UI and pipeline orchestration
â”œâ”€â”€ voice_of_the_patient.py   # Speech-to-text (Whisper)
â”œâ”€â”€ brain_of_the_doctor.py    # LLM reasoning (Groq)
â”œâ”€â”€ voice_of_the_doctor.py    # Text-to-speech (gTTS)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

````

---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Create a Virtual Environment (Recommended)

```bash
conda create -n ai_doctor python=3.10
conda activate ai_doctor
````

### 2ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Set Groq API Key

In `brain_of_the_doctor.py`:

```python
client = Groq(api_key="YOUR_GROQ_API_KEY")
```

(For production, use environment variables.)

### 4ï¸âƒ£ Run the Application

```bash
streamlit run streamlit_app.py
```

Allow microphone access when prompted ğŸ™ï¸

---

## ğŸ“¦ Dependencies Explained

| Library   | Purpose                             |
| --------- | ----------------------------------- |
| Streamlit | Web UI & audio input                |
| Whisper   | Speech-to-Text + language detection |
| Groq SDK  | LLM inference (LLaMA-3)             |
| gTTS      | Text-to-Speech                      |
| Torch     | Deep learning backend               |

---

## ğŸ§ª NLP Concepts Demonstrated

* Multilingual representation learning
* Cross-lingual semantic understanding
* Transformer-based speech recognition
* Prompt engineering for LLMs
* End-to-end multimodal NLP pipeline
* Language-agnostic response generation

---

## ğŸ§  Why This Project Is Industry-Relevant

âœ” Demonstrates **prior multilingual NLP experience**
âœ” Uses **modern LLM infrastructure (Groq)**
âœ” Avoids naive translation-based pipelines
âœ” Applies NLP to **healthcare domain**
âœ” Modular, scalable design

---

## ğŸ§¾ Interview-Ready Explanation (Use This)

> â€œI built a multilingual voice-enabled healthcare chatbot using Whisper for speech recognition and Groqâ€™s LLaMA-3 model for multilingual natural language understanding and response generation. The system automatically understands and responds in the userâ€™s original language, demonstrating cross-lingual NLP capabilities without explicit translation.â€

---

## âš ï¸ Disclaimer

This chatbot provides **general health information only** and is **not a substitute for professional medical advice, diagnosis, or treatment**.

---

## ğŸš€ Future Enhancements

* Conversation memory
* Medical intent classification
* Retrieval-Augmented Generation (RAG)
* Higher-quality neural TTS
* Deployment on Streamlit Cloud / Docker

```
